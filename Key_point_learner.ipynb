{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Summary Chapter 6 - Key point model"},{"metadata":{},"cell_type":"markdown","source":"In this example we are going to train a model to identify a certain point in an image. In this case it is the center of the head in images of people. The dataset we are using is called Biwi Kinect Head Pose dataset. \n\nLet's first include everthing we need and fetch the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#hide\n!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\nfrom fastbook import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = untar_data(URLs.BIWI_HEAD_POSE)\nPath.BASE_PATH = path","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data comprises 24 folders (for 24 different people). Each of those comprises a number of images (poses) with each a txt file which specifies the coordinates of the head center key point.<br>\nLet's get the image files and name them according to the poses."},{"metadata":{"trusted":true},"cell_type":"code","source":"img_files = get_image_files(path)\ndef img2pose(x): return Path(f'{str(x)[:-7]}pose.txt')\nimg2pose(img_files[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can take a look at shape and a thump of one image using:<br>\n```python\nim = PILImage.create(img_files[0])\nim.shape<br>\n```\nand<br>\n```python\nim.to_thumb(160)\n```"},{"metadata":{},"cell_type":"markdown","source":"We need to define a fct that turns the txt file into a two item tensor with the coordinates of the key points. In the case of the Biwi data this is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)\ndef get_ctr(f):\n    ctr = np.genfromtxt(img2pose(f), skip_header=3)\n    c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]\n    c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]\n    return tensor([c1,c2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this we can create a DataBlock object with an ImageBlock and a PointBlock. With the present data it is important to not randomly split all files, since it's only 24 people with different poses. We will use only one person's images as validation set. Hence, we make sure that the training hasn't seen this person before. <br>\nWhen using a Pointblock fastAI knows that we are dealing with coordinates and applies any augmentation also to the coordinates."},{"metadata":{"trusted":true},"cell_type":"code","source":"biwi = DataBlock(\n    blocks=(ImageBlock, PointBlock),\n    get_items=get_image_files,\n    get_y=get_ctr,\n    splitter=FuncSplitter(lambda o: o.parent.name=='13'),\n    batch_tfms=[*aug_transforms(size=(240,320)), \n                Normalize.from_stats(*imagenet_stats)]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now for the DataLoader. We also want to check a minibatch: "},{"metadata":{"trusted":true},"cell_type":"code","source":"dls = biwi.dataloaders(path)\ndls.show_batch(max_n=9, figsize=(8,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we create the learner. We are also going to specify the range of the targets (coordinates). Coordinates always get rescaled to -1:1, hence the y_range."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(dls, resnet18, y_range=(-1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If the loss fct isn't explicitly defined fastAI is going to choose automatically. In this case\n\n```python\ndls.loss_func\n```\nis FlattenedLoss of MSELoss()"},{"metadata":{},"cell_type":"markdown","source":"We can use the lr-finder to find a good learn rate, use it to fine tune and take a look at the results:"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-2\nlearn.fine_tune(3, lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.show_results(ds_idx=1, nrows=3, figsize=(6,8))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}